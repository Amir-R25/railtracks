{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call LLMs\n",
    "Some of the more exciting use cases for RC is when you want to cede control of the decision making process to the LLM. RC has a suite of tools that you can use to make this process much simpler. Check out an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:29:52.656653Z",
     "start_time": "2025-03-19T01:29:50.496308Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Set, Type\n",
    "from pydantic import BaseModel, Field\n",
    "import src.requestcompletion as rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:29:53.717937Z",
     "start_time": "2025-03-19T01:29:53.698088Z"
    }
   },
   "outputs": [],
   "source": [
    "class HarshCritic(rc.library.TerminalLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a harsh critic of the world and you should analyze the given statement and provide a harsh critique of it. Be very concise and to the point.\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            message_history: rc.llm.MessageHistory,\n",
    "    ):\n",
    "        message_history.insert(0, rc.llm.SystemMessage(self.system_message()))\n",
    "        super().__init__(\n",
    "            message_history=message_history,\n",
    "            model=self.create_model(),\n",
    "        )\n",
    "\n",
    "    def create_model(self) -> rc.llm.ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Harsh Critic\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> rc.llm.Tool:\n",
    "        return rc.llm.Tool(\n",
    "            name=\"Harsh_Critic\",\n",
    "            detail=\"A tool used to critique a statement harshly.\",\n",
    "            parameters={rc.llm.Parameter(\"analysis_detail\", \"string\", \"The thing you would like to analyze\")}\n",
    "            \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> rc.library.TerminalLLM:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:29:54.374280Z",
     "start_time": "2025-03-19T01:29:54.359281Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositiveCritic(rc.library.TerminalLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a positive critic of the world and you should analyze the given statement and provide a positive critique of it. Be very concise and to the point.\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            message_history: rc.llm.MessageHistory,\n",
    "    ):\n",
    "        message_history.insert(0, rc.llm.SystemMessage(self.system_message()))\n",
    "        super().__init__(\n",
    "            message_history=message_history,\n",
    "            model=self.create_model(),\n",
    "        )\n",
    "\n",
    "    def create_model(self) -> rc.llm.ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Positive Critic\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> rc.llm.Tool:\n",
    "        return rc.llm.Tool(\n",
    "            name=\"Positive_Critic\",\n",
    "            detail=\"A tool used to critique a statement positively.\",\n",
    "            parameters={rc.llm.Parameter(\"analysis_detail\", \"string\", \"The thing you would like to analyze\")}\n",
    "            \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> rc.library.TerminalLLM:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:29:54.938320Z",
     "start_time": "2025-03-19T01:29:54.933323Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeeperMeaningCritic(rc.library.TerminalLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a critic of the world and you should analyze the given statement and provide a deep meaning critic of it. Be very concise and to the point.\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_model(cls) -> rc.llm.ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            message_history: rc.llm.MessageHistory\n",
    "    ):\n",
    "        message_history.insert(0, rc.llm.SystemMessage(self.system_message()))\n",
    "        super().__init__(\n",
    "            message_history=message_history,\n",
    "            model=self.create_model(),\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Deeper Meaning Critic\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> rc.llm.Tool:\n",
    "        return rc.llm.Tool(\n",
    "            name=\"Deeper_Meaning_Critic\",\n",
    "            detail=\"A tool used to critique a statement.\",\n",
    "            parameters={rc.llm.Parameter(\"analysis_detail\", \"string\", \"The thing you would like to analyze\",)}\n",
    "            \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> rc.library.TerminalLLM:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_critic = rc.llm.SystemMessage(\"You are a critic of the world and you provide comprehensive critiques of the world around you. You should utilize the provided tools to collect specific critiques and structure them before completing your answer.\")\n",
    "Critic = rc.library.tool_call_llm(connected_nodes={HarshCritic, PositiveCritic, DeeperMeaningCritic},\n",
    "                                  pretty_name=\"Critic\", \n",
    "                                  system_message=system_message_critic, \n",
    "                                  model=rc.llm.OpenAILLM(\"gpt-4o\"),\n",
    "                                #   output_type=\"MessageHistory\",\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:28.862705Z",
     "start_time": "2025-03-19T01:30:28.837702Z"
    }
   },
   "outputs": [],
   "source": [
    "template = (\"I am writing a short story and I would like to analyze my introduction.\\n\"\n",
    "            \"\\n\"\n",
    "            \"Once upon a time there was a little boy who lived in a small village. He was a very kind and generous, but lacked an understanding\"\n",
    "            \" of the world around him. He was always looking for ways to help others and make the world a better place. One day, he stumbled upon a\"\n",
    "            \" magical book that would change his life forever. The book was filled with stories of adventure and mystery, and the promise of a better\"\n",
    "            \" tomorrow.\")\n",
    "with rc.Runner(executor_config=rc.run.ExecutorConfig(timeout=50)) as runner:\n",
    "    response = await runner.run(Critic, message_history=rc.llm.MessageHistory([rc.llm.UserMessage(template)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assistant: Your introduction beautifully captures the essence of innocence and innate goodness in a child's heart. The little boy's kindness and generosity set a positive example for readers. His discovery of the magical book symbolizes the transformative power of knowledge and imagination, suggesting that even simple beginnings can lead to profound personal growth and a brighter future. The narrative encourages curiosity and the pursuit of understanding, highlighting the potential for positive change when one is open to learning and adventure."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there may be a need to inject parameters into the subserviant tools at instance \"runtime\". This can be done by modifying the node creation method in the parent top level node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredSummarizerOutput(BaseModel):\n",
    "    positive_critique: str = Field(description=\"The positive critique\")\n",
    "    harsh_critique: str = Field(description=\"The harsh critique\")\n",
    "    overall_score: float = Field(description=\"The overall score of the critique (on a scale of 0 to 100)\")\n",
    "    summary: str = Field(description=\"The summary of all the critiques\")\n",
    "            \n",
    "class StructureSummarizerCritic(rc.library.StructuredLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a reviwer tool that summarizes the critiques and structures it.\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            message_history: rc.llm.MessageHistory,\n",
    "    ):\n",
    "        message_history.insert(0, rc.llm.SystemMessage(self.system_message()))\n",
    "        super().__init__(\n",
    "            message_history=message_history,\n",
    "            model=self.create_model(),\n",
    "        )\n",
    "\n",
    "    def create_model(self) -> rc.llm.ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "    \n",
    "    def output_model(self) -> StructuredSummarizerOutput:\n",
    "        return StructuredSummarizerOutput\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Structured Summarizer\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> rc.llm.Tool:\n",
    "        return rc.llm.Tool(\n",
    "            name=\"Structure_and_Summarize\",\n",
    "            detail=\"A tool used to generate summaries of critiques and structure them.\",\n",
    "            parameters={rc.llm.Parameter(\"positive_critique\", \"string\", \"The positive critique\"),\n",
    "                        rc.llm.Parameter(\"harsh_critique\", \"string\", \"The harsh critique\"),\n",
    "                        rc.llm.Parameter(\"overall_score\", \"float\", \"The overall score of the critique. Give only a number between 0 and 100\"),\n",
    "                        rc.llm.Parameter(\"summary\", \"string\", \"The summary of all the critiques\")\n",
    "                        }   \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> rc.library.TerminalLLM:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(f\"Positive Critique: {tool_parameters['positive_critique']}\"), \n",
    "                                              rc.llm.UserMessage(f\"Harsh Critique: {tool_parameters['harsh_critique']}\"),\n",
    "                                              rc.llm.UserMessage(f\"Overall Score: {tool_parameters['overall_score']}\"),\n",
    "                                              rc.llm.UserMessage(f\"Summary: {tool_parameters['summary']}\"),\n",
    "                                              ])\n",
    "        return cls(message_hist)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeLevelHarshCritic(HarshCritic):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            message_history: rc.llm.MessageHistory,\n",
    "            grade_level: int\n",
    "    ):\n",
    "        super().__init__(message_history=message_history)\n",
    "        self.grade_level = grade_level\n",
    "\n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters):\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist, tool_parameters[\"grade_level\"])\n",
    "        \n",
    "\n",
    "    def system_message(self):\n",
    "        return super().system_message() + \" You should provide a critique at a grade level of \" + str(self.grade_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InjectGradeLevel(Critic):\n",
    "    def __init__(\n",
    "            self,\n",
    "            message_history: rc.llm.MessageHistory,\n",
    "            grade_level: int\n",
    "    ):\n",
    "        super().__init__(message_history=message_history)\n",
    "        self.grade_level = grade_level\n",
    "\n",
    "    def create_node(self, tool_name: str, arguments: Dict[str, Any]) -> rc.Node:\n",
    "        if tool_name == \"Harsh_Critic\":\n",
    "            arguments[\"grade_level\"] = self.grade_level\n",
    "            return GradeLevelHarshCritic.prepare_tool(arguments)\n",
    "        # note the super method will not add any parameters and work just as it always does.\n",
    "        return super().create_node(tool_name, arguments)\n",
    "\n",
    "\n",
    "    def connected_nodes(self) -> Set[Type[rc.Node]]:\n",
    "        # note that you can add the new node to the connected nodes set\n",
    "        return {GradeLevelHarshCritic, PositiveCritic, DeeperMeaningCritic}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T00:58:52.182005Z",
     "start_time": "2025-02-12T00:58:51.968968Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rc\u001b[38;5;241m.\u001b[39mRunner(executor_config\u001b[38;5;241m=\u001b[39mrc\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mExecutorConfig(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m      5\u001b[0m     response \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mrun(InjectGradeLevel(\n\u001b[0;32m      6\u001b[0m         message_history\u001b[38;5;241m=\u001b[39mrc\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mMessageHistory([rc\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mUserMessage(template)]),\n\u001b[0;32m      7\u001b[0m         grade_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m),\n\u001b[0;32m      8\u001b[0m     )\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manswer\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'answer'"
     ]
    }
   ],
   "source": [
    "template = (\"I am writing a short story and I would like to analyze my introduction.\\n\"\n",
    "            \"\\n\"\n",
    "            \"Green Apples are a strong fruit that can be used in many different ways. They are a great source of vitamins and minerals, and can be eaten or even thrown at others you don't like\")\n",
    "with rc.Runner(executor_config=rc.run.ExecutorConfig(timeout=50)) as runner:\n",
    "    response = runner.run(InjectGradeLevel(\n",
    "        message_history=rc.llm.MessageHistory([rc.llm.UserMessage(template)]),\n",
    "        grade_level=12),\n",
    "    )\n",
    "\n",
    "\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
