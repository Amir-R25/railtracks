{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call LLMs\n",
    "Some of the more exciting use cases for RC is when you want to cede control of the decision making process to the LLM. RC has a suite of tools that you can use to make this process much simpler. Check out an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Set, Type\n",
    "\n",
    "from railtownai_rc.nodes import Node\n",
    "from typing_extensions import Self\n",
    "\n",
    "import railtownai_rc as rc\n",
    "from railtownai_rc.llm import ModelBase, Tool\n",
    "\n",
    "from src.railtownai_rc.llm import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarshCritic(rc.nodes.library.TerminalLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a harsh critic of the world and you should analyze the given statement and provide a harsh critique of it.\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_model(cls) -> ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Harsh Critic\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> Tool:\n",
    "        return Tool(\n",
    "            name=\"Harsh_Critic\",\n",
    "            detail=\"A tool used to critique a statement harshly.\",\n",
    "            parameters={Parameter(\"analysis_detail\", \"string\", \"The thing you would like to analyze\")}\n",
    "            \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> Self:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositiveCritic(rc.nodes.library.TerminalLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a positive critic of the world and you should analyze the given statement and provide a positive critique of it.\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_model(cls) -> ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Positive Critic\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> Tool:\n",
    "        return Tool(\n",
    "            name=\"Positive_Critic\",\n",
    "            detail=\"A tool used to critique a statement positively.\",\n",
    "            parameters={Parameter(\"analysis_detail\", \"string\", \"The thing you would like to analyze\")}\n",
    "            \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> Self:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperMeaningCritic(rc.nodes.library.TerminalLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls):\n",
    "        return \"You are a critic of the world and you should analyze the given statement and provide a critique of it.\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_model(cls) -> ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Deeper Meaning Critic\"\n",
    "    \n",
    "    # for types which you want to connect to an LLM using our tooling you should implement this method\n",
    "    @classmethod\n",
    "    def tool_info(cls) -> Tool:\n",
    "        return Tool(\n",
    "            name=\"Deeper_Meaning_Critic\",\n",
    "            detail=\"A tool used to critique a statement.\",\n",
    "            parameters={Parameter(\"analysis_detail\", \"string\", \"The thing you would like to analyze\",)}\n",
    "            \n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> Self:\n",
    "        message_hist = rc.llm.MessageHistory([rc.llm.UserMessage(tool_parameters[\"analysis_detail\"])])\n",
    "        return cls(message_hist)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(rc.nodes.library.ToolCallLLM):\n",
    "    @classmethod\n",
    "    def system_message(cls) -> str:\n",
    "        return \"You are a critic of the world and you provide comprehensive critiques of the world around you. You should utilize the provided tools to collect specific critiques before completing your answer.\"\n",
    "\n",
    "    @classmethod\n",
    "    def create_model(cls) -> ModelBase:\n",
    "        return rc.llm.OpenAILLM(\"gpt-4o\")\n",
    "\n",
    "    @classmethod\n",
    "    def tool_details(cls) -> Set[Type[Node]]:\n",
    "        return {HarshCritic, PositiveCritic, DeeperMeaningCritic}\n",
    "\n",
    "    @classmethod\n",
    "    def pretty_name(cls) -> str:\n",
    "        return \"Critic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Logan\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\nodes\\nodes.py:109: UserWarning: You are using the default context. It will be empty.\n",
      "  warnings.warn(\"You are using the default context. It will be empty.\")\n"
     ]
    },
    {
     "ename": "ExecutionException",
     "evalue": "The final nodes exception was Execution timed out after 25 seconds, in the failed request RequestTemplate(START, None, 00ceb4da-d8fb-4328-9c79-4cc8860725a2, None, Stamp(time=1738625505.844137, step=0, identifier='Opened a new request between the start and the Critic')).A complete history of errors seen is seen here: \n []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\run\\state\\execute.py:128\u001b[0m, in \u001b[0;36mRCState.execute\u001b[1;34m(self, start_node)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutor_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# before exit we must update the state objects one last time\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# this is a special case becuase in all other situations we call `_run_requests` and it handles the\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# updating of the state objects.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:460\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutionException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m template \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am writing a short story and I would like to analyze my introduction.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnce upon a time there was a little boy who lived in a small village. He was a very kind and generous, but lacked an understanding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m of the world around him. He was always looking for ways to help others and make the world a better place. One day, he stumbled upon a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m magical book that would change his life forever. The book was filled with stories of adventure and mystery, and the promise of a better\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m tomorrow.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCritic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUserMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39manswer)\n",
      "File \u001b[1;32m~\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\run\\run.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(start_node, context, subscriber, executor_config)\u001b[0m\n\u001b[0;32m     30\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe do not support the injection of context at this time. We will use empty context\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     context \u001b[38;5;241m=\u001b[39m EmptyContext()\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mExecutionInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubscriber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\run\\run.py:52\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(start_node, executor_info)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(start_node: Node, executor_info: ExecutionInfo) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExecutionInfo:\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    Runs the given node handling any calls to other nodes eventually returning the finished result.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unsafe_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_info\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\run\\run.py:63\u001b[0m, in \u001b[0;36m_unsafe_run\u001b[1;34m(start_node, executor_info)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_unsafe_run\u001b[39m(\n\u001b[0;32m     56\u001b[0m     start_node: Node,\n\u001b[0;32m     57\u001b[0m     executor_info: ExecutionInfo,\n\u001b[0;32m     58\u001b[0m ):\n\u001b[0;32m     59\u001b[0m     state \u001b[38;5;241m=\u001b[39m RCState(\n\u001b[0;32m     60\u001b[0m         execution_info\u001b[38;5;241m=\u001b[39mexecutor_info,\n\u001b[0;32m     61\u001b[0m     )\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# note the state object is pass by reference so this works well.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\u001b[38;5;241m.\u001b[39minfo\n",
      "File \u001b[1;32m~\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\run\\state\\execute.py:118\u001b[0m, in \u001b[0;36mRCState.invoke\u001b[1;34m(self, start_node)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     99\u001b[0m     start_node: Node,\n\u001b[0;32m    100\u001b[0m ):\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    This function will run the provided node and will automatically handle any calls to other nodes that are made\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    during the execution of the node.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\rc\\.venv\\lib\\site-packages\\railtownai_rc\\run\\state\\execute.py:140\u001b[0m, in \u001b[0;36mRCState.execute\u001b[1;34m(self, start_node)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_answer \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mTimeoutError:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExecutionException(\n\u001b[0;32m    141\u001b[0m         failed_request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_heap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTART\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    142\u001b[0m         execution_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo,\n\u001b[0;32m    143\u001b[0m         final_exception\u001b[38;5;241m=\u001b[39mGlobalTimeOut(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor_config\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m### if the initial request throws a scorched earth exception will have to handle it here.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ScorchedEarthException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mExecutionException\u001b[0m: The final nodes exception was Execution timed out after 25 seconds, in the failed request RequestTemplate(START, None, 00ceb4da-d8fb-4328-9c79-4cc8860725a2, None, Stamp(time=1738625505.844137, step=0, identifier='Opened a new request between the start and the Critic')).A complete history of errors seen is seen here: \n []"
     ]
    }
   ],
   "source": [
    "template = (\"I am writing a short story and I would like to analyze my introduction.\\n\"\n",
    "            \"\\n\"\n",
    "            \"Once upon a time there was a little boy who lived in a small village. He was a very kind and generous, but lacked an understanding\"\n",
    "            \" of the world around him. He was always looking for ways to help others and make the world a better place. One day, he stumbled upon a\"\n",
    "            \" magical book that would change his life forever. The book was filled with stories of adventure and mystery, and the promise of a better\"\n",
    "            \" tomorrow.\")\n",
    "\n",
    "response = rc.run.run(Critic(\n",
    "    message_history=rc.llm.MessageHistory([rc.llm.UserMessage(template)]),\n",
    "))\n",
    "\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
