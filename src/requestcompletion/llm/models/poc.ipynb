{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9195fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requestcompletion.llm.models._litellm_wrapper import LiteLLMWrapper\n",
    "from src.requestcompletion.llm import ToolCall, Tool, Parameter\n",
    "from src.requestcompletion.llm.message import UserMessage, SystemMessage, AssistantMessage, ToolMessage, ToolResponse\n",
    "from src.requestcompletion.llm.history import MessageHistory\n",
    "from pydantic import BaseModel\n",
    "import litellm\n",
    "from typing import List\n",
    "import src.requestcompletion as rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db4891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LiteLLMWrapper with the desired model\n",
    "litellm_model = rc.llm.AnthropicLLM(model_name=\"anthropic/claude-3-5-sonnet-20241022\")\n",
    "# litellm_model = rc.llm.OpenAILLM(model_name=\"openai/gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23243f",
   "metadata": {},
   "source": [
    "## General chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8d0def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a classic one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "Because they make up everything! ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "# Create a message history\n",
    "messages = MessageHistory([\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    UserMessage(\"Can you tell me a joke?\")\n",
    "])\n",
    "\n",
    "# Perform a chat completion\n",
    "response = litellm_model.chat(messages)\n",
    "\n",
    "# Print the assistant's response\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281ee08",
   "metadata": {},
   "source": [
    "## Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db50776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DishInfo(BaseModel):\n",
    "    name: str\n",
    "    cuisine: str\n",
    "    calories: int\n",
    "\n",
    "messages = MessageHistory([\n",
    "    SystemMessage(\"You are a nutrition expert\"),\n",
    "    UserMessage(\"Tell me about a popular Italian dish.\"),\n",
    "])\n",
    "\n",
    "result = litellm_model.structured(messages, DishInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805321ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DishInfo(name='Spaghetti Carbonara', cuisine='Italian', calories=450)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0269f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine(BaseModel):\n",
    "    manufacturing_country: str\n",
    "    number_of_cylinders: int\n",
    "\n",
    "class CarInfo(BaseModel):\n",
    "    brand: str\n",
    "    country: str\n",
    "    engine: Engine\n",
    "\n",
    "class Info(BaseModel):\n",
    "    cars: List[CarInfo]\n",
    "\n",
    "sports_cars_description = \"\"\"\n",
    "Among the worldâ€™s most thrilling sports cars, the Ferrari 812 Superfast, crafted in Italy,\n",
    "features a naturally aspirated V12 engine also built in Italy, delivering blistering power\n",
    "through its 12-cylinder setup. From Germany, the Porsche 911 Turbo S stands out with its\n",
    "twin-turbocharged flat-six engine, manufactured in Germany, offering a perfect balance of\n",
    "performance and refinement. Meanwhile, the Chevrolet Corvette Z06, proudly American-made\n",
    "in the USA, houses a hand-built 5.5-liter flat-plane crank V8 engine, also produced in the\n",
    "USA, boasting 8 cylinders of raw muscle. The McLaren 720S, a British marvel from the UK,\n",
    "is equipped with a twin-turbo V8 engine made in England, showcasing 8 cylinders of\n",
    "precision engineering. Finally, the Toyota GR Supra, originating from Japan, uses a\n",
    "3.0-liter inline-6 engine built in Austria by BMW, blending Japanese design with German\n",
    "power and offering 6 cylinders of smooth performance.\n",
    "\"\"\"\n",
    "\n",
    "messages = MessageHistory(\n",
    "    [\n",
    "        SystemMessage(\"You are a car enthusiast who can extract information from paragraphs about different cars.\"\\\n",
    "                                  \"Ensure you analyze the whole paragraph and return information about all cars mentioned\"),\n",
    "        UserMessage(f\"Extract the information about all of the cars mentioned in: \\n {sports_cars_description}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = litellm_model.structured(messages, Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62eb80a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Info(cars=[CarInfo(brand='Ferrari 812 Superfast', country='Italy', engine=Engine(manufacturing_country='Italy', number_of_cylinders=12)), CarInfo(brand='Porsche 911 Turbo S', country='Germany', engine=Engine(manufacturing_country='Germany', number_of_cylinders=6)), CarInfo(brand='Chevrolet Corvette Z06', country='USA', engine=Engine(manufacturing_country='USA', number_of_cylinders=8)), CarInfo(brand='McLaren 720S', country='UK', engine=Engine(manufacturing_country='England', number_of_cylinders=8)), CarInfo(brand='Toyota GR Supra', country='Japan', engine=Engine(manufacturing_country='Austria', number_of_cylinders=6))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140d85d",
   "metadata": {},
   "source": [
    "## Stream chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb7065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = MessageHistory([\n",
    "    UserMessage(\"Can you tell me a joke?\")\n",
    "])\n",
    "\n",
    "resp = litellm_model.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55791d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object LiteLLMWrapper.stream_chat.<locals>.streamer at 0x0000029DDFD16B90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438e6c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "'s a classic one:\n",
      "\n",
      "Why don't scientists\n",
      " trust atoms?\n",
      "Because they make up everything\n",
      "! ðŸ˜„\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in resp.streamer:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235986f0",
   "metadata": {},
   "source": [
    "## Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27d0e8",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_locations() -> List[str]:\n",
    "    \"\"\"Returns a list of available locations.\n",
    "    Args:\n",
    "    Returns:\n",
    "        List[str]: A list of available locations.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"New York\",\n",
    "        \"Los Angeles\",\n",
    "        \"Chicago\",\n",
    "        \"Delhi\",\n",
    "        \"Mumbai\",\n",
    "        \"Bangalore\",\n",
    "        \"Paris\",\n",
    "        \"Denmark\",\n",
    "        \"Sweden\",\n",
    "        \"Norway\",\n",
    "        \"Germany\",\n",
    "        \"Vancouver\",\n",
    "        \"Toronto\",\n",
    "    ]\n",
    "\n",
    "def currency_used(location: str) -> str:\n",
    "    \"\"\"Returns the currency used in a location.\n",
    "    Args:\n",
    "        location (str): The location to get the currency used for.\n",
    "    Returns:\n",
    "        str: The currency used in the location.\n",
    "    \"\"\"\n",
    "    currency_map = {\n",
    "        \"New York\": \"USD\",\n",
    "        \"Los Angeles\": \"USD\",\n",
    "        \"Chicago\": \"USD\",\n",
    "        \"Delhi\": \"INR\",\n",
    "        \"Mumbai\": \"INR\",\n",
    "        \"Bangalore\": \"INR\",\n",
    "        \"Paris\": \"EUR\",\n",
    "        \"Denmark\": \"EUR\",\n",
    "        \"Sweden\": \"EUR\",\n",
    "        \"Norway\": \"EUR\",\n",
    "        \"Germany\": \"EUR\",\n",
    "        \"Vancouver\": \"CAD\",\n",
    "        \"Toronto\": \"CAD\",\n",
    "    }\n",
    "    used_currency = currency_map.get(location)\n",
    "    if used_currency is None:\n",
    "        raise ValueError(f\"Currency not available for location: {location}\")\n",
    "    return used_currency\n",
    "\n",
    "def average_location_cost(location: str, num_days: int) -> float:\n",
    "    \"\"\"Returns the average cost of living in a location for a given number of days.\n",
    "    Args:\n",
    "        location (str): The location to get the cost of living for.\n",
    "        num_days (int): The number of days for the trip.\n",
    "    Returns:\n",
    "        float: The average cost of living in the location.\n",
    "    \"\"\"\n",
    "    daily_costs = {\n",
    "        \"New York\": 200.0,\n",
    "        \"Los Angeles\": 180.0,\n",
    "        \"Chicago\": 150.0,\n",
    "        \"Delhi\": 50.0,\n",
    "        \"Mumbai\": 55.0,\n",
    "        \"Bangalore\": 60.0,\n",
    "        \"Paris\": 220.0,\n",
    "        \"Denmark\": 250.0,\n",
    "        \"Sweden\": 240.0,\n",
    "        \"Norway\": 230.0,\n",
    "        \"Germany\": 210.0,\n",
    "        \"Vancouver\": 200.0,\n",
    "        \"Toronto\": 180.0,\n",
    "    }\n",
    "    daily_cost = daily_costs.get(location)\n",
    "    if daily_cost is None:\n",
    "        raise ValueError(f\"Cost information not available for location: {location}\")\n",
    "    return daily_cost * num_days\n",
    "\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> float:\n",
    "    \"\"\"Converts currency using a static exchange rate (for testing purposes).\n",
    "    Args:\n",
    "        amount (float): The amount to convert.\n",
    "        from_currency (str): The currency to convert from.\n",
    "        to_currency (str): The currency to convert to.\n",
    "    Returns:\n",
    "        float: The converted amount.\n",
    "    Raises:\n",
    "        ValueError: If the exchange rate is not available.\n",
    "    \"\"\"\n",
    "    exchange_rates = {\n",
    "        (\"USD\", \"EUR\"): 0.85,\n",
    "        (\"EUR\", \"USD\"): 1.1765,\n",
    "        (\"USD\", \"INR\"): 83.0,\n",
    "        (\"INR\", \"USD\"): 0.01205,\n",
    "        (\"EUR\", \"INR\"): 98.0,\n",
    "        (\"INR\", \"EUR\"): 0.0102,\n",
    "        (\"CAD\", \"USD\"): 0.78,\n",
    "        (\"USD\", \"CAD\"): 1.28,\n",
    "        (\"CAD\", \"EUR\"): 0.66,\n",
    "        (\"EUR\", \"CAD\"): 1.52,\n",
    "        (\"INR\", \"CAD\"): 0.0125,\n",
    "        (\"CAD\", \"INR\"): 80.0,\n",
    "    }\n",
    "\n",
    "    rate = exchange_rates.get((from_currency, to_currency))\n",
    "    if rate is None:\n",
    "        raise ValueError(\"Exchange rate not available\")\n",
    "    return amount * rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bad7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First LLM Response:\n",
      " ModelResponse(id='chatcmpl-9223ee9a-09c0-4884-b229-ff1049149104', created=1748370309, model='claude-3-sonnet-20240229', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=\"Here's a summary for a 2-day trip to New York City:\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"location\": \"New York\", \"num_days\": 2}', name='average_location_cost'), id='toolu_01CfLVYLrVG8ovv7rgaZJPY4', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=92, prompt_tokens=397, total_tokens=489, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), cache_creation_input_tokens=0, cache_read_input_tokens=0))\n",
      "\n",
      "Length of tool calls 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import litellm\n",
    "\n",
    "# model = \"gpt-3.5-turbo-1106\"\n",
    "# model = \"gpt-4o\"\n",
    "model = \"claude-3-sonnet-20240229\"\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    elif \"new york\" in location.lower():\n",
    "        return json.dumps({\"location\": \"New York\", \"temperature\": \"75\", \"unit\": \"fahrenheit\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "def average_location_cost(location: str, num_days: int) -> float:\n",
    "    \"\"\"Returns the average cost of living in a location for a given number of days.\n",
    "    Args:\n",
    "        location (str): The location to get the cost of living for, e.g. \"New York\"\n",
    "        num_days (int): The number of days for the trip.\n",
    "    Returns:\n",
    "        float: The average cost of living in the location.\n",
    "    \"\"\"\n",
    "    daily_costs = {\n",
    "        \"New York\": 200.0,\n",
    "        \"Los Angeles\": 180.0,\n",
    "        \"Chicago\": 150.0,\n",
    "        \"Delhi\": 50.0,\n",
    "        \"Mumbai\": 55.0,\n",
    "        \"Bangalore\": 60.0,\n",
    "        \"Paris\": 220.0,\n",
    "        \"Denmark\": 250.0,\n",
    "        \"Sweden\": 240.0,\n",
    "        \"Norway\": 230.0,\n",
    "        \"Germany\": 210.0,\n",
    "        \"Vancouver\": 200.0,\n",
    "        \"Toronto\": 180.0,\n",
    "    }\n",
    "    daily_cost = daily_costs.get(location)\n",
    "    if daily_cost is None:\n",
    "        raise ValueError(f\"Cost information not available for location: {location}\")\n",
    "    return daily_cost * num_days\n",
    "\n",
    "\n",
    "# Step 1: send the conversation and available functions to the model\n",
    "messages = [{\"role\": \"user\", \"content\": \"Give me a summary for 2 day trip to New York. Use NewYork as an arg if ou are tool_calling\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"average_location_cost\",\n",
    "            \"description\": \"Get the average cost of living in a location for a given number of days\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The location to get the cost of living for.\",\n",
    "                    },\n",
    "                    \"num_days\": {\"type\": \"integer\", \"description\": \"The number of days for the trip\"},\n",
    "                },\n",
    "                \"required\": [\"location\", \"num_days\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = litellm.completion(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "print(\"\\nFirst LLM Response:\\n\", response)\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "print(\"\\nLength of tool calls\", len(tool_calls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ea5667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'New York', 'num_days': 2}\n",
      "400.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: check if the model wanted to call a function\n",
    "if tool_calls:\n",
    "    # Step 3: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"average_location_cost\": average_location_cost,\n",
    "    }  \n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "    # Step 4: send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        print(function_args)\n",
    "        function_response = function_to_call(**function_args)\n",
    "        print(function_response)\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_response),\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52bd7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Give me a summary for 2 day trip to New York. Use NewYork as an arg if ou are tool_calling'}\n"
     ]
    }
   ],
   "source": [
    "print(messages[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ed7a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Give me a summary for 2 day trip to New York. Use NewYork as an arg if ou are tool_calling'}, Message(content=\"Here's a summary for a 2-day trip to New York City:\", role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"location\": \"New York\", \"num_days\": 2}', name='average_location_cost'), id='toolu_01CfLVYLrVG8ovv7rgaZJPY4', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}), {'tool_call_id': 'toolu_01CfLVYLrVG8ovv7rgaZJPY4', 'role': 'tool', 'name': 'average_location_cost', 'content': '400.0'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryan\\dev\\rc\\myenv\\lib\\site-packages\\pydantic\\main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'index': 1, 'function': ...Y4', 'type': 'function'}, input_type=dict])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second LLM response:\n",
      " ModelResponse(id='chatcmpl-dc4ead0e-f274-446d-b245-41007eeefd05', created=1748370311, model='claude-3-sonnet-20240229', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='Based on the average location cost tool, a 2-day trip to New York City for one person would cost around $400 for accommodation, meals, and basic expenses.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=1, function=Function(arguments='{\"location\": \"New York, NY\", \"unit\": \"fahrenheit\"}', name='get_current_weather'), id='toolu_01ASKobiYWV23cfA7fvS3XbZ', type='function')], function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=114, prompt_tokens=503, total_tokens=617, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None), cache_creation_input_tokens=0, cache_read_input_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(messages)\n",
    "second_response = litellm.completion(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")  # get a new response from the model where it can see the function response\n",
    "print(\"\\nSecond LLM response:\\n\", second_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8819a40",
   "metadata": {},
   "source": [
    "### RC: chat_with_tools invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6202ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_instances = [\n",
    "    Tool(\n",
    "        name=\"average_location_cost\",\n",
    "        detail=\"Get the average cost of living in a location for a given number of days\",\n",
    "        parameters={\n",
    "            Parameter(\n",
    "                name=\"location\",\n",
    "                param_type=\"string\",\n",
    "                description=\"The location to get the cost of living for.\",\n",
    "                required=True\n",
    "            ),\n",
    "            Parameter(\n",
    "                name=\"num_days\",\n",
    "                param_type=\"integer\",\n",
    "                description=\"The number of days for the trip\",\n",
    "                required=True\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_current_weather\",\n",
    "        detail=\"Get the current weather in a given location\",\n",
    "        parameters={\n",
    "            Parameter(\n",
    "                name=\"location\",\n",
    "                param_type=\"string\",\n",
    "                description=\"The city and state, e.g. San Francisco, CA\",\n",
    "                required=True\n",
    "            ),\n",
    "            Parameter(\n",
    "                name=\"unit\",\n",
    "                param_type=\"string\",\n",
    "                description=\"The unit to use for temperature (celsius or fahrenheit)\",\n",
    "                required=False\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35dcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = MessageHistory([SystemMessage(\"You are a travel agent with access to the following tools: get_current_weather, avergae_location_cost\"),\n",
    "                           UserMessage(\"Give me a summary for 2 day trip to New York. Use New York as an arg if ou are tool_calling\"),\n",
    "                          ])\n",
    "first_response = litellm_model.chat_with_tools(messages, tool_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaaa0aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First LLM Response:\n",
      " assistant: [ToolCall(identifier='toolu_019FQBKuezeeTn18nFmkKaTa', name='get_current_weather', arguments={'location': 'New York'}), ToolCall(identifier='toolu_01PcWTkgbfphQFGwaozdLi13', name='average_location_cost', arguments={'location': 'New York', 'num_days': 2})]\n",
      "\n",
      "Length of tool calls 2\n",
      "After Tool Calls:  system: You are a travel agent with access to the following tools: get_current_weather, avergae_location_cost\n",
      "user: Give me a summary for 2 day trip to New York. Use New York as an arg if ou are tool_calling\n",
      "assistant: [ToolCall(identifier='toolu_019FQBKuezeeTn18nFmkKaTa', name='get_current_weather', arguments={'location': 'New York'}), ToolCall(identifier='toolu_01PcWTkgbfphQFGwaozdLi13', name='average_location_cost', arguments={'location': 'New York', 'num_days': 2})]\n",
      "tool: get_current_weather -> {\"location\": \"New York\", \"temperature\": \"75\", \"unit\": \"fahrenheit\"}\n",
      "tool: average_location_cost -> 400.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryan\\dev\\rc\\myenv\\lib\\site-packages\\pydantic\\main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...Ta', 'type': 'function'}, input_type=dict])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...13', 'type': 'function'}, input_type=dict])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second LLM response:\n",
      " assistant: Based on the data I've gathered, here's a summary for your 2-day trip to New York:\n",
      "\n",
      "Weather:\n",
      "- Current temperature in New York is 75Â°F, which is quite pleasant for exploring the city.\n",
      "\n",
      "Cost:\n",
      "- The average cost for a 2-day stay in New York would be approximately $400. This typically includes basic accommodations and daily expenses.\n",
      "\n",
      "Keep in mind that:\n",
      "1. The weather can change, so it's good to check closer to your travel date\n",
      "2. The cost is an average estimate - actual expenses can vary depending on your choice of accommodations, dining preferences, and activities\n",
      "3. New York can be quite expensive compared to many other cities, so it's good to budget accordingly\n",
      "\n",
      "Would you like any specific information about attractions or areas to stay in New York?\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst LLM Response:\\n\", first_response)\n",
    "response_message = first_response.message.content\n",
    "tool_calls = [tool_call for tool_call in response_message if isinstance(tool_call, ToolCall)]\n",
    "\n",
    "print(\"\\nLength of tool calls\", len(tool_calls))\n",
    "\n",
    "if tool_calls:\n",
    "    # Step 3: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"average_location_cost\": average_location_cost,\n",
    "    }  \n",
    "    messages.append(AssistantMessage(response_message))  # extend conversation with assistant's reply\n",
    "\n",
    "    # Step 4: send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_response = function_to_call(**tool_call.arguments)\n",
    "\n",
    "        messages.append(\n",
    "            ToolMessage(content=ToolResponse(identifier=tool_call.identifier, result=str(function_response), name=function_name))\n",
    "        )\n",
    "print(\"After Tool Calls: \", messages)\n",
    "\n",
    "second_response = litellm_model.chat_with_tools(messages, tool_instances)\n",
    "print(\"\\nSecond LLM response:\\n\", second_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af879c",
   "metadata": {},
   "source": [
    "# LiteLLM integrated RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a8025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requestcompletion import llm\n",
    "import src.requestcompletion as rc\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bd0a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrate(BaseModel):\n",
    "    integrand: str = Field(description=\"The function you want to integrate in Latex\")\n",
    "    lower_limit: float = Field(description=\"The lower limit of the integral\")\n",
    "    upper_limit: float = Field(description=\"The upper limit of the integral\")\n",
    "\n",
    "\n",
    "class Simplify(BaseModel):\n",
    "    expression: str = Field(description=\"The expression you want to simplify in Latex\")\n",
    "\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    result: str = Field(description=\"The result of the tool call\")\n",
    "    key_challenges: str = Field(\n",
    "        description=\"The key challenges faced encountered during the tool call\"\n",
    "    )\n",
    "\n",
    "\n",
    "tools = [\n",
    "    llm.Tool(\n",
    "        name=\"integrate\",\n",
    "        detail=\"A tool to evaluate math expressions\",\n",
    "        parameters=Integrate,\n",
    "    ),\n",
    "    llm.Tool(\n",
    "        name=\"simplify\", detail=\"A tool to evaluate math expressions\", parameters=Simplify\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f909cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class integrate_tool(rc.Node):\n",
    "    def __init__(self, integrand, lower_limit, upper_limit):\n",
    "        super().__init__()\n",
    "\n",
    "    async def invoke(self) -> float:\n",
    "        return 1.5\n",
    "    \n",
    "    @classmethod\n",
    "    def tool_info(self) -> rc.llm.Tool:\n",
    "        return tools[0]\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(self) -> str:\n",
    "        return \"integrate\"\n",
    "\n",
    "class simplify_tool(rc.Node):\n",
    "    def __init__(self, expression):\n",
    "        super().__init__()\n",
    "\n",
    "    async def invoke(self) -> str:\n",
    "        return \"x + 1\"\n",
    "    \n",
    "    @classmethod\n",
    "    def tool_info(self) -> rc.llm.Tool:\n",
    "        return tools[1]\n",
    "    \n",
    "    @classmethod\n",
    "    def pretty_name(self) -> str:\n",
    "        return \"simplify\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5455221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(integrand: str, lower_limit: float, upper_limit: float) -> float:\n",
    "    \"\"\"Integrate a function from lower limit to upper limit\n",
    "    Args:\n",
    "        integrand (str): The function you want to integrate in Latex\n",
    "        lower_limit (float): The lower limit of the integral\n",
    "        upper_limit (float): The upper limit of the integral\n",
    "    Returns:\n",
    "        float: The result of the integration\n",
    "    \"\"\"\n",
    "\n",
    "    return 1.5\n",
    "\n",
    "def simplify(expression: str) -> str:\n",
    "    \"\"\"Simplify an expression\n",
    "    Args:\n",
    "        expression (str): The expression you want to simplify in Latex\n",
    "    Returns:\n",
    "        str: The simplified expression\n",
    "    \"\"\"\n",
    "    return \"x + 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8434eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_agent = rc.library.tool_call_llm(\n",
    "                                      connected_nodes=[integrate_tool, simplify_tool],\n",
    "                                      # connected_nodes=[rc.library.from_function(integrate), rc.library.from_function(simplify)],\n",
    "                                      pretty_name=\"Math Agent\",\n",
    "                                      model=rc.llm.AnthropicLLM(\"claude-3-sonnet-20240229\"),\n",
    "                                      # model=rc.llm.OpenAILLM(\"gpt-4o\"),\n",
    "                                      system_message=rc.llm.SystemMessage(\"You are a helpful assistant that can use tools to help the user.\"),\n",
    "                                      output_model=FinalResponse\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99079fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[+23.486 s] RC.RUNNER   : INFO     - START CREATED Math Agent - (, message_history=user: What is the integral of x^2/x + 1 from [0, 1]?)\n",
      "[+25.802 s] RC.RUNNER   : INFO     - Math Agent CREATED integrate - ({'integrand': '\\\\frac{x^2}{x+1}', 'lower_limit': 0, 'upper_limit': 1}, )\n",
      "[+25.807 s] RC.RUNNER   : INFO     - integrate DONE 1.5\n",
      "c:\\Users\\Aryan\\dev\\rc\\myenv\\lib\\site-packages\\pydantic\\main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `ChatCompletionMessageToolCall` - serialized value may not be as expected [input_value={'function': {'arguments'...GD', 'type': 'function'}, input_type=dict])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "[+27.963 s] RC.RUNNER   : INFO     - Math Agent CREATED FinalResponse - (, message_history=user: system: You are a helpful assistant that can use tools to help the user.\n",
      "user: What is the integral of x^2/x + 1 from [0, 1]?\n",
      "assistant: [ToolCall(identifier='toolu_013MDsF2SinCQYJCixBFWMGD', name='integrate', arguments={'integrand': '\\\\frac{x^2}{x+1}', 'lower_limit': 0, 'upper_limit': 1})]\n",
      "tool: integrate -> 1.5\n",
      "assistant: To evaluate the integral of x^2/(x+1) from 0 to 1, I used the \"integrate\" tool by providing the integrand expression in LaTeX form as \"\\frac{x^2}{x+1}\", the lower limit as 0, and the upper limit as 1. The tool returned the value 1.5 as the result of this definite integral.)\n",
      "[+29.594 s] RC.RUNNER   : INFO     - FinalResponse DONE result='1.5' key_challenges='Integrating a rational function required using a symbolic integration tool.'\n",
      "[+29.598 s] RC.RUNNER   : INFO     - Math Agent DONE result='1.5' key_challenges='Integrating a rational function required using a symbolic integration tool.'\n"
     ]
    }
   ],
   "source": [
    "message_history = llm.MessageHistory(\n",
    "    [\n",
    "        llm.UserMessage(\"What is the integral of x^2/x + 1 from [0, 1]?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = await rc.call(math_agent, message_history=message_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "153dad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "Integrating a rational function required using a symbolic integration tool.\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(response, FinalResponse)\n",
    "print(response.result)\n",
    "print(response.key_challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78153d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
