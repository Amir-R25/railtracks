{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requestcompletion.llm.models._litellm_wrapper import LiteLLMWrapper\n",
    "from src.requestcompletion.llm import ToolCall, Tool, Parameter\n",
    "from src.requestcompletion.llm.message import UserMessage, SystemMessage, AssistantMessage\n",
    "from src.requestcompletion.llm.history import MessageHistory\n",
    "from pydantic import BaseModel\n",
    "import litellm\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LiteLLMWrapper with the desired model\n",
    "# litellm_model = LiteLLMWrapper(model_name=\"anthropic/claude-3-5-sonnet-20241022\")\n",
    "litellm_model = LiteLLMWrapper(model_name=\"openai/gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23243f",
   "metadata": {},
   "source": [
    "## General chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message history\n",
    "messages = MessageHistory([\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    UserMessage(\"Can you tell me a joke?\")\n",
    "])\n",
    "\n",
    "# Perform a chat completion\n",
    "response = litellm_model.chat(messages)\n",
    "\n",
    "# Print the assistant's response\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281ee08",
   "metadata": {},
   "source": [
    "## Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db50776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DishInfo(BaseModel):\n",
    "    name: str\n",
    "    cuisine: str\n",
    "    calories: int\n",
    "\n",
    "messages = MessageHistory([\n",
    "    SystemMessage(\"You are a nutrition expert\"),\n",
    "    UserMessage(\"Tell me about a popular Italian dish.\"),\n",
    "])\n",
    "\n",
    "result = litellm_model.structured(messages, DishInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805321ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0269f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine(BaseModel):\n",
    "    manufacturing_country: str\n",
    "    number_of_cylinders: int\n",
    "\n",
    "class CarInfo(BaseModel):\n",
    "    brand: str\n",
    "    country: str\n",
    "    engine: Engine\n",
    "\n",
    "class Info(BaseModel):\n",
    "    cars: List[CarInfo]\n",
    "\n",
    "sports_cars_description = \"\"\"\n",
    "Among the worldâ€™s most thrilling sports cars, the Ferrari 812 Superfast, crafted in Italy,\n",
    "features a naturally aspirated V12 engine also built in Italy, delivering blistering power\n",
    "through its 12-cylinder setup. From Germany, the Porsche 911 Turbo S stands out with its\n",
    "twin-turbocharged flat-six engine, manufactured in Germany, offering a perfect balance of\n",
    "performance and refinement. Meanwhile, the Chevrolet Corvette Z06, proudly American-made\n",
    "in the USA, houses a hand-built 5.5-liter flat-plane crank V8 engine, also produced in the\n",
    "USA, boasting 8 cylinders of raw muscle. The McLaren 720S, a British marvel from the UK,\n",
    "is equipped with a twin-turbo V8 engine made in England, showcasing 8 cylinders of\n",
    "precision engineering. Finally, the Toyota GR Supra, originating from Japan, uses a\n",
    "3.0-liter inline-6 engine built in Austria by BMW, blending Japanese design with German\n",
    "power and offering 6 cylinders of smooth performance.\n",
    "\"\"\"\n",
    "\n",
    "messages = MessageHistory(\n",
    "    [\n",
    "        SystemMessage(\"You are a car enthusiast who can extract information from paragraphs about different cars.\"\\\n",
    "                                  \"Ensure you analyze the whole paragraph and return information about all cars mentioned\"),\n",
    "        UserMessage(f\"Extract the information about all of the cars mentioned in: \\n {sports_cars_description}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = litellm_model.structured(messages, Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140d85d",
   "metadata": {},
   "source": [
    "## Stream chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = MessageHistory([\n",
    "    UserMessage(\"Can you tell me a joke?\")\n",
    "])\n",
    "\n",
    "resp = litellm_model.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55791d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in resp.streamer:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235986f0",
   "metadata": {},
   "source": [
    "## Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27d0e8",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_locations() -> List[str]:\n",
    "    \"\"\"Returns a list of available locations.\n",
    "    Args:\n",
    "    Returns:\n",
    "        List[str]: A list of available locations.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"New York\",\n",
    "        \"Los Angeles\",\n",
    "        \"Chicago\",\n",
    "        \"Delhi\",\n",
    "        \"Mumbai\",\n",
    "        \"Bangalore\",\n",
    "        \"Paris\",\n",
    "        \"Denmark\",\n",
    "        \"Sweden\",\n",
    "        \"Norway\",\n",
    "        \"Germany\",\n",
    "        \"Vancouver\",\n",
    "        \"Toronto\",\n",
    "    ]\n",
    "\n",
    "def currency_used(location: str) -> str:\n",
    "    \"\"\"Returns the currency used in a location.\n",
    "    Args:\n",
    "        location (str): The location to get the currency used for.\n",
    "    Returns:\n",
    "        str: The currency used in the location.\n",
    "    \"\"\"\n",
    "    currency_map = {\n",
    "        \"New York\": \"USD\",\n",
    "        \"Los Angeles\": \"USD\",\n",
    "        \"Chicago\": \"USD\",\n",
    "        \"Delhi\": \"INR\",\n",
    "        \"Mumbai\": \"INR\",\n",
    "        \"Bangalore\": \"INR\",\n",
    "        \"Paris\": \"EUR\",\n",
    "        \"Denmark\": \"EUR\",\n",
    "        \"Sweden\": \"EUR\",\n",
    "        \"Norway\": \"EUR\",\n",
    "        \"Germany\": \"EUR\",\n",
    "        \"Vancouver\": \"CAD\",\n",
    "        \"Toronto\": \"CAD\",\n",
    "    }\n",
    "    used_currency = currency_map.get(location)\n",
    "    if used_currency is None:\n",
    "        raise ValueError(f\"Currency not available for location: {location}\")\n",
    "    return used_currency\n",
    "\n",
    "def average_location_cost(location: str, num_days: int) -> float:\n",
    "    \"\"\"Returns the average cost of living in a location for a given number of days.\n",
    "    Args:\n",
    "        location (str): The location to get the cost of living for.\n",
    "        num_days (int): The number of days for the trip.\n",
    "    Returns:\n",
    "        float: The average cost of living in the location.\n",
    "    \"\"\"\n",
    "    daily_costs = {\n",
    "        \"New York\": 200.0,\n",
    "        \"Los Angeles\": 180.0,\n",
    "        \"Chicago\": 150.0,\n",
    "        \"Delhi\": 50.0,\n",
    "        \"Mumbai\": 55.0,\n",
    "        \"Bangalore\": 60.0,\n",
    "        \"Paris\": 220.0,\n",
    "        \"Denmark\": 250.0,\n",
    "        \"Sweden\": 240.0,\n",
    "        \"Norway\": 230.0,\n",
    "        \"Germany\": 210.0,\n",
    "        \"Vancouver\": 200.0,\n",
    "        \"Toronto\": 180.0,\n",
    "    }\n",
    "    daily_cost = daily_costs.get(location)\n",
    "    if daily_cost is None:\n",
    "        raise ValueError(f\"Cost information not available for location: {location}\")\n",
    "    return daily_cost * num_days\n",
    "\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> float:\n",
    "    \"\"\"Converts currency using a static exchange rate (for testing purposes).\n",
    "    Args:\n",
    "        amount (float): The amount to convert.\n",
    "        from_currency (str): The currency to convert from.\n",
    "        to_currency (str): The currency to convert to.\n",
    "    Returns:\n",
    "        float: The converted amount.\n",
    "    Raises:\n",
    "        ValueError: If the exchange rate is not available.\n",
    "    \"\"\"\n",
    "    exchange_rates = {\n",
    "        (\"USD\", \"EUR\"): 0.85,\n",
    "        (\"EUR\", \"USD\"): 1.1765,\n",
    "        (\"USD\", \"INR\"): 83.0,\n",
    "        (\"INR\", \"USD\"): 0.01205,\n",
    "        (\"EUR\", \"INR\"): 98.0,\n",
    "        (\"INR\", \"EUR\"): 0.0102,\n",
    "        (\"CAD\", \"USD\"): 0.78,\n",
    "        (\"USD\", \"CAD\"): 1.28,\n",
    "        (\"CAD\", \"EUR\"): 0.66,\n",
    "        (\"EUR\", \"CAD\"): 1.52,\n",
    "        (\"INR\", \"CAD\"): 0.0125,\n",
    "        (\"CAD\", \"INR\"): 80.0,\n",
    "    }\n",
    "\n",
    "    rate = exchange_rates.get((from_currency, to_currency))\n",
    "    if rate is None:\n",
    "        raise ValueError(\"Exchange rate not available\")\n",
    "    return amount * rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987d5d9",
   "metadata": {},
   "source": [
    "### LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# model = \"gpt-3.5-turbo-1106\"\n",
    "# model = \"gpt-4o\"\n",
    "model = \"claude-3-sonnet-20240229\"\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    elif \"new york\" in location.lower():\n",
    "        return json.dumps({\"location\": \"New York\", \"temperature\": \"75\", \"unit\": \"fahrenheit\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "def average_location_cost(location: str, num_days: int) -> float:\n",
    "    \"\"\"Returns the average cost of living in a location for a given number of days.\n",
    "    Args:\n",
    "        location (str): The location to get the cost of living for, e.g. \"New York\"\n",
    "        num_days (int): The number of days for the trip.\n",
    "    Returns:\n",
    "        float: The average cost of living in the location.\n",
    "    \"\"\"\n",
    "    daily_costs = {\n",
    "        \"New York\": 200.0,\n",
    "        \"Los Angeles\": 180.0,\n",
    "        \"Chicago\": 150.0,\n",
    "        \"Delhi\": 50.0,\n",
    "        \"Mumbai\": 55.0,\n",
    "        \"Bangalore\": 60.0,\n",
    "        \"Paris\": 220.0,\n",
    "        \"Denmark\": 250.0,\n",
    "        \"Sweden\": 240.0,\n",
    "        \"Norway\": 230.0,\n",
    "        \"Germany\": 210.0,\n",
    "        \"Vancouver\": 200.0,\n",
    "        \"Toronto\": 180.0,\n",
    "    }\n",
    "    daily_cost = daily_costs.get(location)\n",
    "    if daily_cost is None:\n",
    "        raise ValueError(f\"Cost information not available for location: {location}\")\n",
    "    return daily_cost * num_days\n",
    "\n",
    "def test_parallel_function_call():\n",
    "    try:\n",
    "        # Step 1: send the conversation and available functions to the model\n",
    "        messages = [{\"role\": \"user\", \"content\": \"Give me a summary for 2 day trip to New York. Use NewYork as an arg if ou are tool_calling\"}]\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"average_location_cost\",\n",
    "                    \"description\": \"Get the average cost of living in a location for a given number of days\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The location to get the cost of living for.\",\n",
    "                            },\n",
    "                            \"num_days\": {\"type\": \"integer\", \"description\": \"The number of days for the trip\"},\n",
    "                        },\n",
    "                        \"required\": [\"location\", \"num_days\"],\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_current_weather\",\n",
    "                    \"description\": \"Get the current weather in a given location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "        response = litellm.completion(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "        )\n",
    "        print(\"\\nFirst LLM Response:\\n\", response)\n",
    "        response_message = response.choices[0].message\n",
    "        tool_calls = response_message.tool_calls\n",
    "\n",
    "        print(\"\\nLength of tool calls\", len(tool_calls))\n",
    "\n",
    "        # Step 2: check if the model wanted to call a function\n",
    "        if tool_calls:\n",
    "            # Step 3: call the function\n",
    "            # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "            available_functions = {\n",
    "                \"get_current_weather\": get_current_weather,\n",
    "                \"average_location_cost\": average_location_cost,\n",
    "            }  \n",
    "            messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "            # Step 4: send the info for each function call and function response to the model\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                print(function_args)\n",
    "                function_response = function_to_call(**function_args)\n",
    "                print(function_response)\n",
    "\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(function_response),\n",
    "                    }\n",
    "                )  # extend conversation with function response\n",
    "\n",
    "            print(messages)\n",
    "            second_response = litellm.completion(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "            )  # get a new response from the model where it can see the function response\n",
    "            print(\"\\nSecond LLM response:\\n\", second_response)\n",
    "            return second_response\n",
    "    except Exception as e:\n",
    "      print(f\"Error occurred: {e}\")\n",
    "\n",
    "x = test_parallel_function_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_instances = [\n",
    "    Tool(\n",
    "        name=\"average_location_cost\",\n",
    "        detail=\"Get the average cost of living in a location for a given number of days\",\n",
    "        parameters={\n",
    "            Parameter(\n",
    "                name=\"location\",\n",
    "                param_type=\"string\",\n",
    "                description=\"The location to get the cost of living for.\",\n",
    "                required=True\n",
    "            ),\n",
    "            Parameter(\n",
    "                name=\"num_days\",\n",
    "                param_type=\"integer\",\n",
    "                description=\"The number of days for the trip\",\n",
    "                required=True\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_current_weather\",\n",
    "        detail=\"Get the current weather in a given location\",\n",
    "        parameters={\n",
    "            Parameter(\n",
    "                name=\"location\",\n",
    "                param_type=\"string\",\n",
    "                description=\"The city and state, e.g. San Francisco, CA\",\n",
    "                required=True\n",
    "            ),\n",
    "            Parameter(\n",
    "                name=\"unit\",\n",
    "                param_type=\"string\",\n",
    "                description=\"The unit to use for temperature (celsius or fahrenheit)\",\n",
    "                required=False\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35dcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = MessageHistory([SystemMessage(\"You are a travel agent with access to the following tools: get_current_weather, avergae_location_cost\"),\n",
    "                           UserMessage(\"Give me a summary for 2 day trip to New York. Use NewYork as an arg if ou are tool_calling\"),\n",
    "                          ])\n",
    "response = litellm_model.chat_with_tools(messages, tool_instances)\n",
    "messages.append(response.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ed196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_litellm_message(msg):\n",
    "    \"\"\"\n",
    "    Convert your Message (UserMessage, AssistantMessage, ToolMessage) into\n",
    "    the simple dict format that litellm.completion expects.\n",
    "    \"\"\"\n",
    "    base = {\"role\": msg.role, \"content\": msg.content}\n",
    "    return base\n",
    "\n",
    "messages = [_to_litellm_message(m) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst LLM Response:\\n\", response)\n",
    "response_message = response.message.content\n",
    "tool_calls = [tool_call for tool_call in response_message if isinstance(tool_call, ToolCall)]\n",
    "\n",
    "print(\"\\nLength of tool calls\", len(tool_calls))\n",
    "\n",
    "if tool_calls:\n",
    "    # Step 3: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"average_location_cost\": average_location_cost,\n",
    "    }  \n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "    # Step 4: send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        print(tool_call.arguments)\n",
    "        function_response = function_to_call(**tool_call.arguments)\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.identifier,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_response),\n",
    "            }\n",
    "        )  # extend conversation with function response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa274706",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = litellm.completion(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")  # get a new response from the model where it can see the function response\n",
    "print(\"\\nSecond LLM response:\\n\", second_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1ef8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66af879c",
   "metadata": {},
   "source": [
    "# LiteLLM integrated RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd0a9a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SystemMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequestcompletion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrc\u001b[39;00m\n\u001b[0;32m      3\u001b[0m terminal \u001b[38;5;241m=\u001b[39m rc\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mterminal_llm(pretty_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerminal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                    model\u001b[38;5;241m=\u001b[39mrc\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mOpenAILLM(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m----> 5\u001b[0m                                    system_message\u001b[38;5;241m=\u001b[39m\u001b[43mSystemMessage\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m                                    )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SystemMessage' is not defined"
     ]
    }
   ],
   "source": [
    "import requestcompletion as rc\n",
    "\n",
    "terminal = rc.library.terminal_llm(pretty_name=\"Terminal\",\n",
    "                                   model=rc.llm.OpenAILLM(\"gpt-4o\"),\n",
    "                                   system_message=SystemMessage(\"You are a helpful assistant.\"),\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await rc.call(terminal, message_history=MessageHistory([UserMessage(\"How are you doing?\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181eea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
